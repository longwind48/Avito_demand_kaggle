{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightgbm Implementation Avito w/ target encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By: Traci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook builds off several public kernels on kaggle. \n",
    "\n",
    "Instead of using label encoding of categorical features, I used target encoding (aka mean encoding).\n",
    "\n",
    "Data can be downloaded from https://www.kaggle.com/c/avito-demand-prediction.\n",
    "\n",
    "More information can be found in readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:\n",
      " ['aggregated_features.csv', 'aggregated_features_v3.csv', 'aggregated_features_v5.csv', 'periods_test.csv', 'periods_train.csv', 'target_encoded.csv', 'test.csv', 'train.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\longwind48\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Initially forked from Bojan's kernel here: https://www.kaggle.com/tunguz/bow-meta-text-and-dense-features-lb-0-2242/code\n",
    "#improvement using kernel from Nick Brook's kernel here: https://www.kaggle.com/nicapotato/bow-meta-text-and-dense-features-lgbm\n",
    "#Used oof method from Faron's kernel here: https://www.kaggle.com/mmueller/stacking-starter?scriptVersionId=390867\n",
    "#Used some text cleaning method from Muhammad Alfiansyah's kernel here: https://www.kaggle.com/muhammadalfiansyah/push-the-lgbm-v19\n",
    "#Forked From - https://www.kaggle.com/him4318/avito-lightgbm-with-ridge-feature-v-2-0\n",
    "\n",
    "import time\n",
    "notebookstart= time.time()\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "random.seed(2018)\n",
    "print(\"Data:\\n\",os.listdir(\"data\"))\n",
    "\n",
    "# Models Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Gradient Boosting\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "# Tf-Idf\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "# Viz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "\n",
    "NFOLDS = 5\n",
    "SEED = 2018\n",
    "VALID = True\n",
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, seed=0, params=None, seed_bool = True):\n",
    "        if(seed_bool == True):\n",
    "            params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "        \n",
    "def get_oof(clf, x_train, y, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        print('\\nFold {}'.format(i))\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
    "    \n",
    "def cleanName(text):\n",
    "    try:\n",
    "        textProc = text.lower()\n",
    "        # textProc = \" \".join(map(str.strip, re.split('(\\d+)',textProc)))\n",
    "        #regex = re.compile(u'[^[:alpha:]]')\n",
    "        #textProc = regex.sub(\" \", textProc)\n",
    "        textProc = re.sub('[!@#$_“”¨«»®´·º½¾¿¡§£₤‘’]', '', textProc)\n",
    "        textProc = \" \".join(textProc.split())\n",
    "        return textProc\n",
    "    except: \n",
    "        return \"name error\"\n",
    "    \n",
    "    \n",
    "def rmse(y, y0):\n",
    "    assert len(y) == len(y0)\n",
    "    return np.sqrt(np.mean(np.power((y - y0), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "testing = pd.read_csv('data/test.csv', index_col = \"item_id\", parse_dates = [\"activation_date\"])#.sample(1000)\n",
    "testdex = testing.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Load Stage\n",
      "Train shape: 1503424 Rows, 17 Columns\n",
      "Test shape: 508438 Rows, 16 Columns\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData Load Stage\")\n",
    "training = pd.read_csv('data/train.csv', index_col = \"item_id\", parse_dates = [\"activation_date\"])#.sample(1000)\n",
    "traindex = training.index\n",
    "testing = pd.read_csv('data/test.csv', index_col = \"item_id\", parse_dates = [\"activation_date\"])#.sample(1000)\n",
    "testdex = testing.index\n",
    "\n",
    "ntrain = training.shape[0]\n",
    "ntest = testing.shape[0]\n",
    "\n",
    "kf = KFold(ntrain, n_folds=NFOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "y = training.deal_probability.copy()\n",
    "#training.drop(\"deal_probability\",axis=1, inplace=True)\n",
    "print('Train shape: {} Rows, {} Columns'.format(*training.shape))\n",
    "print('Test shape: {} Rows, {} Columns'.format(*testing.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combine Train and Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Data shape: 2011862 Rows, 17 Columns\n"
     ]
    }
   ],
   "source": [
    "print(\"Combine Train and Test\")\n",
    "df = pd.concat([training,testing],axis=0)\n",
    "#del training, testing\n",
    "gc.collect()\n",
    "print('\\nAll Data shape: {} Rows, {} Columns'.format(*df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Add in aggregated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index()\n",
    "gp = pd.read_csv('data/aggregated_features.csv') \n",
    "df = df.merge(gp, on='user_id', how='left')\n",
    "del gp\n",
    "gc.collect()\n",
    "#df = df.set_index('item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in log\n",
      "  \n",
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in log\n",
      "  \n",
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in log\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Engineering\")\n",
    "df[\"price\"] = np.log(df[\"price\"]+0.001)\n",
    "df[\"price\"].fillna(df.price.mean(),inplace=True)\n",
    "df[\"image_top_1\"].fillna(-999,inplace=True)\n",
    "\n",
    "df[\"avg_days_up_user\"] = np.log(df[\"avg_days_up_user\"]+0.001)\n",
    "df[\"avg_days_up_user\"].fillna(-999,inplace=True)\n",
    "df[\"avg_times_up_user\"] = np.log(df[\"avg_times_up_user\"]+0.001)\n",
    "df[\"avg_times_up_user\"].fillna(-999,inplace=True)\n",
    "df[\"n_user_items\"] = np.log(df[\"n_user_items\"]+0.001)\n",
    "df[\"n_user_items\"].fillna(-999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Create Time Variables\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCreate Time Variables\")\n",
    "df[\"Weekday\"] = df['activation_date'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.drop([\"activation_date\",\"image\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Text feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Text Features\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nText Features\")\n",
    "\n",
    "# Feature Engineering \n",
    "\n",
    "# Meta Text Features\n",
    "textfeats = [\"description\", \"title\"]\n",
    "df['desc_punc'] = df['description'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "\n",
    "df['title'] = df['title'].apply(lambda x: cleanName(x))\n",
    "df[\"description\"]   = df[\"description\"].apply(lambda x: cleanName(x))\n",
    "\n",
    "for cols in textfeats:\n",
    "    df[cols] = df[cols].astype(str) \n",
    "    df[cols] = df[cols].astype(str).fillna('missing') # FILL NA\n",
    "    df[cols] = df[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently\n",
    "    #df[cols + '_num_char'] = df[cols].apply(lambda comment: len(str(comment)))\n",
    "    df[cols + '_num_words'] = df[cols].apply(lambda comment: len(comment.split())) # Count number of Words\n",
    "    df[cols + '_num_unique_words'] = df[cols].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "    df[cols + '_words_vs_unique'] = df[cols+'_num_unique_words'] / df[cols+'_num_words'] * 100 # Count Unique Words\n",
    "    df[cols + '_num_letters'] = df[cols].apply(lambda comment: len(comment)) # Count number of Letters\n",
    "    df[cols + '_num_alphabets'] = df[cols].apply(lambda comment: (comment.count(r'[a-zA-Z]'))) # Count number of Alphabets\n",
    "    df[cols + '_num_alphanumeric'] = df[cols].apply(lambda comment: (comment.count(r'[A-Za-z0-9]'))) # Count number of AlphaNumeric\n",
    "    df[cols + '_num_digits'] = df[cols].apply(lambda comment: (comment.count('[0-9]'))) # Count number of Digits\n",
    "    \n",
    "# Extra Feature Engineering\n",
    "df['avg_len_words_title'] = df['title_num_letters'] / df['title_num_words']\n",
    "df['avg_len_words_desc'] = df['description_num_letters'] / df['description_num_words']\n",
    "df['title_desc_len_ratio'] = df['title_num_letters']/df['description_num_letters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>city</th>\n",
       "      <th>deal_probability</th>\n",
       "      <th>description</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>...</th>\n",
       "      <th>title_num_words</th>\n",
       "      <th>title_num_unique_words</th>\n",
       "      <th>title_words_vs_unique</th>\n",
       "      <th>title_num_letters</th>\n",
       "      <th>title_num_alphabets</th>\n",
       "      <th>title_num_alphanumeric</th>\n",
       "      <th>title_num_digits</th>\n",
       "      <th>avg_len_words_title</th>\n",
       "      <th>avg_len_words_desc</th>\n",
       "      <th>title_desc_len_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b912c3c6a6ad</td>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Екатеринбург</td>\n",
       "      <td>0.12789</td>\n",
       "      <td>кокон для сна малыша,пользовались меньше месяц...</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Постельные принадлежности</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>0.362069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dac0150717d</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>Самара</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>стойка для одежды, под вешалки. с бутика.</td>\n",
       "      <td>692.0</td>\n",
       "      <td>19</td>\n",
       "      <td>Другое</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>0.414634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba83aefab5dc</td>\n",
       "      <td>Аудио и видео</td>\n",
       "      <td>Ростов-на-Дону</td>\n",
       "      <td>0.43177</td>\n",
       "      <td>в хорошем состоянии, домашний кинотеатр с blu ...</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>9</td>\n",
       "      <td>Видео, DVD и Blu-ray плееры</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.823529</td>\n",
       "      <td>0.141414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02996f1dd2ea</td>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Набережные Челны</td>\n",
       "      <td>0.80323</td>\n",
       "      <td>продам кресло от0-25кг</td>\n",
       "      <td>796.0</td>\n",
       "      <td>286</td>\n",
       "      <td>Автомобильные кресла</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c90be56d2ab</td>\n",
       "      <td>Автомобили</td>\n",
       "      <td>Волгоград</td>\n",
       "      <td>0.20797</td>\n",
       "      <td>все вопросы по телефону.</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>3</td>\n",
       "      <td>С пробегом</td>\n",
       "      <td>ВАЗ (LADA)</td>\n",
       "      <td>2110</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id               category_name              city  \\\n",
       "0  b912c3c6a6ad  Товары для детей и игрушки      Екатеринбург   \n",
       "1  2dac0150717d           Мебель и интерьер            Самара   \n",
       "2  ba83aefab5dc               Аудио и видео    Ростов-на-Дону   \n",
       "3  02996f1dd2ea  Товары для детей и игрушки  Набережные Челны   \n",
       "4  7c90be56d2ab                  Автомобили         Волгоград   \n",
       "\n",
       "   deal_probability                                        description  \\\n",
       "0           0.12789  кокон для сна малыша,пользовались меньше месяц...   \n",
       "1           0.00000          стойка для одежды, под вешалки. с бутика.   \n",
       "2           0.43177  в хорошем состоянии, домашний кинотеатр с blu ...   \n",
       "3           0.80323                             продам кресло от0-25кг   \n",
       "4           0.20797                           все вопросы по телефону.   \n",
       "\n",
       "   image_top_1  item_seq_number                      param_1     param_2  \\\n",
       "0       1008.0                2    Постельные принадлежности         NaN   \n",
       "1        692.0               19                       Другое         NaN   \n",
       "2       3032.0                9  Видео, DVD и Blu-ray плееры         NaN   \n",
       "3        796.0              286         Автомобильные кресла         NaN   \n",
       "4       2264.0                3                   С пробегом  ВАЗ (LADA)   \n",
       "\n",
       "  param_3          ...          title_num_words  title_num_unique_words  \\\n",
       "0     NaN          ...                        3                       3   \n",
       "1     NaN          ...                        3                       3   \n",
       "2     NaN          ...                        2                       2   \n",
       "3     NaN          ...                        1                       1   \n",
       "4    2110          ...                        3                       3   \n",
       "\n",
       "  title_words_vs_unique title_num_letters title_num_alphabets  \\\n",
       "0                 100.0                21                   0   \n",
       "1                 100.0                17                   0   \n",
       "2                 100.0                14                   0   \n",
       "3                 100.0                10                   0   \n",
       "4                 100.0                14                   0   \n",
       "\n",
       "  title_num_alphanumeric  title_num_digits  avg_len_words_title  \\\n",
       "0                      0                 0             7.000000   \n",
       "1                      0                 0             5.666667   \n",
       "2                      0                 0             7.000000   \n",
       "3                      0                 0            10.000000   \n",
       "4                      0                 0             4.666667   \n",
       "\n",
       "   avg_len_words_desc  title_desc_len_ratio  \n",
       "0            8.285714              0.362069  \n",
       "1            5.857143              0.414634  \n",
       "2            5.823529              0.141414  \n",
       "3            7.333333              0.454545  \n",
       "4            6.000000              0.583333  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "\n",
    "class MeanEncoder:\n",
    "    def __init__(self, categorical_features, n_splits=5, target_type='regression', prior_weight_func=None):\n",
    "        \"\"\"\n",
    "        :param categorical_features: list of str, the name of the categorical columns to encode\n",
    "\n",
    "        :param n_splits: the number of splits used in mean encoding\n",
    "\n",
    "        :param target_type: str, 'regression' or 'classification'\n",
    "\n",
    "        :param prior_weight_func:\n",
    "        a function that takes in the number of observations, and outputs prior weight\n",
    "        when a dict is passed, the default exponential decay function will be used:\n",
    "        k: the number of observations needed for the posterior to be weighted equally as the prior\n",
    "        f: larger f --> smaller slope\n",
    "        \"\"\"\n",
    "\n",
    "        self.categorical_features = categorical_features\n",
    "        self.n_splits = n_splits\n",
    "        self.learned_stats = {}\n",
    "\n",
    "        if target_type == 'classification':\n",
    "            self.target_type = target_type\n",
    "            self.target_values = []\n",
    "        else:\n",
    "            self.target_type = 'regression'\n",
    "            self.target_values = None\n",
    "\n",
    "        if isinstance(prior_weight_func, dict):\n",
    "            self.prior_weight_func = eval('lambda x: 1 / (1 + np.exp((x - k) / f))', dict(prior_weight_func, np=np))\n",
    "        elif callable(prior_weight_func):\n",
    "            self.prior_weight_func = prior_weight_func\n",
    "        else:\n",
    "            self.prior_weight_func = lambda x: 1 / (1 + np.exp((x - 2) / 1))\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_encode_subroutine(X_train, y_train, X_test, variable, target, prior_weight_func):\n",
    "        X_train = X_train[[variable]].copy()\n",
    "        X_test = X_test[[variable]].copy()\n",
    "\n",
    "        if target is not None:\n",
    "            nf_name = '{}_pred_{}'.format(variable, target)\n",
    "            X_train['pred_temp'] = (y_train == target).astype(int)  # classification\n",
    "        else:\n",
    "            nf_name = '{}_pred'.format(variable)\n",
    "            X_train['pred_temp'] = y_train  # regression\n",
    "        prior = X_train['pred_temp'].mean()\n",
    "\n",
    "        col_avg_y = X_train.groupby(by=variable, axis=0)['pred_temp'].agg({'mean': 'mean', 'beta': 'size'})\n",
    "        col_avg_y['beta'] = prior_weight_func(col_avg_y['beta'])\n",
    "        col_avg_y[nf_name] = col_avg_y['beta'] * prior + (1 - col_avg_y['beta']) * col_avg_y['mean']\n",
    "        col_avg_y.drop(['beta', 'mean'], axis=1, inplace=True)\n",
    "\n",
    "        nf_train = X_train.join(col_avg_y, on=variable)[nf_name].values\n",
    "        nf_test = X_test.join(col_avg_y, on=variable).fillna(prior, inplace=False)[nf_name].values\n",
    "\n",
    "        return nf_train, nf_test, prior, col_avg_y\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        \"\"\"\n",
    "        :param X: pandas DataFrame, n_samples * n_features\n",
    "        :param y: pandas Series or numpy array, n_samples\n",
    "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "        if self.target_type == 'classification':\n",
    "            skf = StratifiedKFold(self.n_splits)\n",
    "        else:\n",
    "            skf = KFold(self.n_splits)\n",
    "\n",
    "        if self.target_type == 'classification':\n",
    "            self.target_values = sorted(set(y))\n",
    "            self.learned_stats = {'{}_pred_{}'.format(variable, target): [] for variable, target in\n",
    "                                  product(self.categorical_features, self.target_values)}\n",
    "            for variable, target in product(self.categorical_features, self.target_values):\n",
    "                nf_name = '{}_pred_{}'.format(variable, target)\n",
    "                X_new.loc[:, nf_name] = np.nan\n",
    "                for large_ind, small_ind in skf.split(y, y):\n",
    "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n",
    "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, target, self.prior_weight_func)\n",
    "                    X_new.iloc[small_ind, -1] = nf_small\n",
    "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n",
    "        else:\n",
    "            self.learned_stats = {'{}_pred'.format(variable): [] for variable in self.categorical_features}\n",
    "            for variable in self.categorical_features:\n",
    "                nf_name = '{}_pred'.format(variable)\n",
    "                X_new.loc[:, nf_name] = np.nan\n",
    "                for large_ind, small_ind in skf.split(y, y):\n",
    "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n",
    "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, None, self.prior_weight_func)\n",
    "                    X_new.iloc[small_ind, -1] = nf_small\n",
    "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n",
    "        return X_new\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        :param X: pandas DataFrame, n_samples * n_features\n",
    "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "\n",
    "        if self.target_type == 'classification':\n",
    "            for variable, target in product(self.categorical_features, self.target_values):\n",
    "                nf_name = '{}_pred_{}'.format(variable, target)\n",
    "                X_new[nf_name] = 0\n",
    "                for prior, col_avg_y in self.learned_stats[nf_name]:\n",
    "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n",
    "                        nf_name]\n",
    "                X_new[nf_name] /= self.n_splits\n",
    "        else:\n",
    "            for variable in self.categorical_features:\n",
    "                nf_name = '{}_pred'.format(variable)\n",
    "                X_new[nf_name] = 0\n",
    "                for prior, col_avg_y in self.learned_stats[nf_name]:\n",
    "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n",
    "                        nf_name]\n",
    "                X_new[nf_name] /= self.n_splits\n",
    "\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cat_vars_orig = [ 'user_id','region', 'city', 'parent_category_name', 'category_name', \n",
    "            'user_type', 'image_top_1', 'param_1', 'param_2', 'param_3'\n",
    "           ]\n",
    "\n",
    "training = training.reset_index()\n",
    "testing = testing.reset_index()\n",
    "\n",
    "mean_encoder = MeanEncoder(categorical_features=cat_vars_orig, prior_weight_func={'k':5, 'f':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paperspace\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:54: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mean_encoded_train = mean_encoder.fit_transform(training, training['deal_probability'])\n",
    "\n",
    "mean_encoded_test = mean_encoder.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Put target encoded features into main df\n",
    "mean_coded_vars = list(set(mean_encoded_train.columns) - set(training.columns))\n",
    "\n",
    "mean_coded_vars.append('item_id')\n",
    "df = pd.merge(df, \n",
    "                     pd.concat([mean_encoded_train[mean_coded_vars], mean_encoded_test[mean_coded_vars]]),\n",
    "                     how='left',\n",
    "                     on='item_id'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.set_index('item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_name</th>\n",
       "      <th>city</th>\n",
       "      <th>deal_probability</th>\n",
       "      <th>description</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>...</th>\n",
       "      <th>user_type_pred</th>\n",
       "      <th>user_id_pred</th>\n",
       "      <th>city_pred</th>\n",
       "      <th>parent_category_name_pred</th>\n",
       "      <th>region_pred</th>\n",
       "      <th>param_2_pred</th>\n",
       "      <th>image_top_1_pred</th>\n",
       "      <th>category_name_pred</th>\n",
       "      <th>param_3_pred</th>\n",
       "      <th>param_1_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b912c3c6a6ad</th>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Екатеринбург</td>\n",
       "      <td>0.12789</td>\n",
       "      <td>кокон для сна малыша,пользовались меньше месяц...</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Постельные принадлежности</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149507</td>\n",
       "      <td>0.139056</td>\n",
       "      <td>0.123217</td>\n",
       "      <td>0.075798</td>\n",
       "      <td>0.121627</td>\n",
       "      <td>0.139056</td>\n",
       "      <td>0.082193</td>\n",
       "      <td>0.197845</td>\n",
       "      <td>0.139056</td>\n",
       "      <td>0.087689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2dac0150717d</th>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>Самара</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>стойка для одежды, под вешалки. с бутика.</td>\n",
       "      <td>692.0</td>\n",
       "      <td>19</td>\n",
       "      <td>Другое</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Для дома и дачи</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149507</td>\n",
       "      <td>0.139056</td>\n",
       "      <td>0.140488</td>\n",
       "      <td>0.179256</td>\n",
       "      <td>0.137626</td>\n",
       "      <td>0.139056</td>\n",
       "      <td>0.171453</td>\n",
       "      <td>0.191640</td>\n",
       "      <td>0.139056</td>\n",
       "      <td>0.126020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba83aefab5dc</th>\n",
       "      <td>Аудио и видео</td>\n",
       "      <td>Ростов-на-Дону</td>\n",
       "      <td>0.43177</td>\n",
       "      <td>в хорошем состоянии, домашний кинотеатр с blu ...</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>9</td>\n",
       "      <td>Видео, DVD и Blu-ray плееры</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Бытовая электроника</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149507</td>\n",
       "      <td>0.140771</td>\n",
       "      <td>0.126286</td>\n",
       "      <td>0.175539</td>\n",
       "      <td>0.136941</td>\n",
       "      <td>0.139056</td>\n",
       "      <td>0.204237</td>\n",
       "      <td>0.173990</td>\n",
       "      <td>0.139056</td>\n",
       "      <td>0.124202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02996f1dd2ea</th>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Набережные Челны</td>\n",
       "      <td>0.80323</td>\n",
       "      <td>продам кресло от0-25кг</td>\n",
       "      <td>796.0</td>\n",
       "      <td>286</td>\n",
       "      <td>Автомобильные кресла</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124325</td>\n",
       "      <td>0.139056</td>\n",
       "      <td>0.135830</td>\n",
       "      <td>0.075798</td>\n",
       "      <td>0.142291</td>\n",
       "      <td>0.139056</td>\n",
       "      <td>0.337333</td>\n",
       "      <td>0.197845</td>\n",
       "      <td>0.139056</td>\n",
       "      <td>0.332130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7c90be56d2ab</th>\n",
       "      <td>Автомобили</td>\n",
       "      <td>Волгоград</td>\n",
       "      <td>0.20797</td>\n",
       "      <td>все вопросы по телефону.</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>3</td>\n",
       "      <td>С пробегом</td>\n",
       "      <td>ВАЗ (LADA)</td>\n",
       "      <td>2110</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149507</td>\n",
       "      <td>0.139056</td>\n",
       "      <td>0.136934</td>\n",
       "      <td>0.262835</td>\n",
       "      <td>0.145426</td>\n",
       "      <td>0.363538</td>\n",
       "      <td>0.319736</td>\n",
       "      <td>0.277869</td>\n",
       "      <td>0.374056</td>\n",
       "      <td>0.282412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           category_name              city  deal_probability  \\\n",
       "item_id                                                                        \n",
       "b912c3c6a6ad  Товары для детей и игрушки      Екатеринбург           0.12789   \n",
       "2dac0150717d           Мебель и интерьер            Самара           0.00000   \n",
       "ba83aefab5dc               Аудио и видео    Ростов-на-Дону           0.43177   \n",
       "02996f1dd2ea  Товары для детей и игрушки  Набережные Челны           0.80323   \n",
       "7c90be56d2ab                  Автомобили         Волгоград           0.20797   \n",
       "\n",
       "                                                    description  image_top_1  \\\n",
       "item_id                                                                        \n",
       "b912c3c6a6ad  кокон для сна малыша,пользовались меньше месяц...       1008.0   \n",
       "2dac0150717d          стойка для одежды, под вешалки. с бутика.        692.0   \n",
       "ba83aefab5dc  в хорошем состоянии, домашний кинотеатр с blu ...       3032.0   \n",
       "02996f1dd2ea                             продам кресло от0-25кг        796.0   \n",
       "7c90be56d2ab                           все вопросы по телефону.       2264.0   \n",
       "\n",
       "              item_seq_number                      param_1     param_2  \\\n",
       "item_id                                                                  \n",
       "b912c3c6a6ad                2    Постельные принадлежности         NaN   \n",
       "2dac0150717d               19                       Другое         NaN   \n",
       "ba83aefab5dc                9  Видео, DVD и Blu-ray плееры         NaN   \n",
       "02996f1dd2ea              286         Автомобильные кресла         NaN   \n",
       "7c90be56d2ab                3                   С пробегом  ВАЗ (LADA)   \n",
       "\n",
       "             param_3 parent_category_name      ...       user_type_pred  \\\n",
       "item_id                                        ...                        \n",
       "b912c3c6a6ad     NaN          Личные вещи      ...             0.149507   \n",
       "2dac0150717d     NaN      Для дома и дачи      ...             0.149507   \n",
       "ba83aefab5dc     NaN  Бытовая электроника      ...             0.149507   \n",
       "02996f1dd2ea     NaN          Личные вещи      ...             0.124325   \n",
       "7c90be56d2ab    2110            Транспорт      ...             0.149507   \n",
       "\n",
       "             user_id_pred city_pred parent_category_name_pred region_pred  \\\n",
       "item_id                                                                     \n",
       "b912c3c6a6ad     0.139056  0.123217                  0.075798    0.121627   \n",
       "2dac0150717d     0.139056  0.140488                  0.179256    0.137626   \n",
       "ba83aefab5dc     0.140771  0.126286                  0.175539    0.136941   \n",
       "02996f1dd2ea     0.139056  0.135830                  0.075798    0.142291   \n",
       "7c90be56d2ab     0.139056  0.136934                  0.262835    0.145426   \n",
       "\n",
       "              param_2_pred  image_top_1_pred  category_name_pred  \\\n",
       "item_id                                                            \n",
       "b912c3c6a6ad      0.139056          0.082193            0.197845   \n",
       "2dac0150717d      0.139056          0.171453            0.191640   \n",
       "ba83aefab5dc      0.139056          0.204237            0.173990   \n",
       "02996f1dd2ea      0.139056          0.337333            0.197845   \n",
       "7c90be56d2ab      0.363538          0.319736            0.277869   \n",
       "\n",
       "              param_3_pred  param_1_pred  \n",
       "item_id                                   \n",
       "b912c3c6a6ad      0.139056      0.087689  \n",
       "2dac0150717d      0.139056      0.126020  \n",
       "ba83aefab5dc      0.139056      0.124202  \n",
       "02996f1dd2ea      0.139056      0.332130  \n",
       "7c90be56d2ab      0.374056      0.282412  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "661"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del training, testing\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dropping original cat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encode Variables\n",
      "Encoding : ['user_id', 'region', 'city', 'parent_category_name', 'category_name', 'user_type', 'image_top_1', 'param_1', 'param_2', 'param_3']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEncode Variables\")\n",
    "categorical = [\"user_id\",\"region\",\"city\",\"parent_category_name\",\"category_name\",\"user_type\",\"image_top_1\",\"param_1\",\"param_2\",\"param_3\"]\n",
    "print(\"Encoding :\",categorical)\n",
    "\n",
    "# # Encoder:\n",
    "# lbl = preprocessing.LabelEncoder()\n",
    "# for col in categorical:\n",
    "#     df[col].fillna('Unknown')\n",
    "#     df[col] = lbl.fit_transform(df[col].astype(str))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.drop(categorical, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##  Term Frequency Inverse Document Frequency Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TF-IDF] Term Frequency Inverse Document Frequency Stage\n",
      "Vectorization Runtime: 12.82 Minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[TF-IDF] Term Frequency Inverse Document Frequency Stage\")\n",
    "russian_stop = set(stopwords.words('russian'))\n",
    "\n",
    "tfidf_para = {\n",
    "    \"stop_words\": russian_stop,\n",
    "    \"analyzer\": 'word',\n",
    "    \"token_pattern\": r'\\w{1,}',\n",
    "    \"sublinear_tf\": True,\n",
    "    \"dtype\": np.float32,\n",
    "    \"norm\": 'l2',\n",
    "    #\"min_df\":5,\n",
    "    #\"max_df\":.9,\n",
    "    \"smooth_idf\":False\n",
    "}\n",
    "\n",
    "\n",
    "def get_col(col_name): return lambda x: x[col_name]\n",
    "##I added to the max_features of the description. It did not change my score much but it may be worth investigating\n",
    "vectorizer = FeatureUnion([\n",
    "        ('description',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=17000,\n",
    "            **tfidf_para,\n",
    "            preprocessor=get_col('description'))),\n",
    "        ('title',CountVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            stop_words = russian_stop,\n",
    "            #max_features=7000,\n",
    "            preprocessor=get_col('title')))\n",
    "    ])\n",
    "    \n",
    "start_vect=time.time()\n",
    "\n",
    "#Fit my vectorizer on the entire dataset instead of the training rows\n",
    "#Score improved by .0001\n",
    "vectorizer.fit(df.to_dict('records'))\n",
    "\n",
    "ready_df = vectorizer.transform(df.to_dict('records'))\n",
    "tfvocab = vectorizer.get_feature_names()\n",
    "print(\"Vectorization Runtime: %0.2f Minutes\"%((time.time() - start_vect)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save/load sparse matrix contructed with tdidf\n",
    "\n",
    "#sparse.save_npz(\"avito_ridge_final/ready_df.npz\", ready_df)\n",
    "ready_df = sparse.load_npz(\"avito_ridge_final/ready_df.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop Text Cols\n",
    "textfeats = [\"description\", \"title\"]\n",
    "df.drop(textfeats, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2011862x1430760 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 48687245 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ready_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0\n",
      "\n",
      "Fold 1\n",
      "\n",
      "Fold 2\n",
      "\n",
      "Fold 3\n",
      "\n",
      "Fold 4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "ridge_params = {'alpha':30.0, 'fit_intercept':True, 'normalize':False, 'copy_X':True,\n",
    "                'max_iter':None, 'tol':0.001, 'solver':'auto', 'random_state':SEED}\n",
    "\n",
    "#Ridge oof method from Faron's kernel\n",
    "#I was using this to analyze my vectorization, but figured it would be interesting to add the results back into the dataset\n",
    "#It doesn't really add much to the score, but it does help lightgbm converge faster\n",
    "ridge = SklearnWrapper(clf=Ridge, seed = SEED, params = ridge_params)\n",
    "ridge_oof_train, ridge_oof_test = get_oof(ridge, ready_df[:ntrain], y, ready_df[ntrain:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge OOF RMSE: 0.23033890453576603\n"
     ]
    }
   ],
   "source": [
    "rms = sqrt(mean_squared_error(y, ridge_oof_train))\n",
    "print('Ridge OOF RMSE: {}'.format(rms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling Stage\n"
     ]
    }
   ],
   "source": [
    "print(\"Modeling Stage\")\n",
    "\n",
    "ridge_preds = np.concatenate([ridge_oof_train, ridge_oof_test])\n",
    "\n",
    "df['ridge_preds'] = ridge_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.drop('deal_probability', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_seq_number                   int64\n",
       "price                           float64\n",
       "avg_days_up_user                float64\n",
       "avg_times_up_user               float64\n",
       "n_user_items                    float64\n",
       "Weekday                           int64\n",
       "desc_punc                         int64\n",
       "description_num_words             int64\n",
       "description_num_unique_words      int64\n",
       "description_words_vs_unique     float64\n",
       "description_num_letters           int64\n",
       "description_num_alphabets         int64\n",
       "description_num_alphanumeric      int64\n",
       "description_num_digits            int64\n",
       "title_num_words                   int64\n",
       "title_num_unique_words            int64\n",
       "title_words_vs_unique           float64\n",
       "title_num_letters                 int64\n",
       "title_num_alphabets               int64\n",
       "title_num_alphanumeric            int64\n",
       "title_num_digits                  int64\n",
       "avg_len_words_title             float64\n",
       "avg_len_words_desc              float64\n",
       "title_desc_len_ratio            float64\n",
       "user_type_pred                  float64\n",
       "user_id_pred                    float64\n",
       "city_pred                       float64\n",
       "parent_category_name_pred       float64\n",
       "region_pred                     float64\n",
       "param_2_pred                    float64\n",
       "image_top_1_pred                float64\n",
       "category_name_pred              float64\n",
       "param_3_pred                    float64\n",
       "param_1_pred                    float64\n",
       "ridge_preds                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1503424 Rows and 1430795 Cols\n",
      "508438 Rows and 1430795 Cols\n",
      "Feature Names Length:  1430795\n"
     ]
    }
   ],
   "source": [
    "# Combine Dense Features with Sparse Text Bag of Words Features\n",
    "X = hstack([csr_matrix(df.loc[traindex,:].values),ready_df[0:traindex.shape[0]]]) # Sparse Matrix\n",
    "testing = hstack([csr_matrix(df.loc[testdex,:].values),ready_df[traindex.shape[0]:]])\n",
    "tfvocab = df.columns.tolist() + tfvocab\n",
    "for shape in [X,testing]:\n",
    "    print(\"{} Rows and {} Cols\".format(*shape.shape))\n",
    "print(\"Feature Names Length: \",len(tfvocab))\n",
    "#del df\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Save/load matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Save and load for train-test sets\n",
    "from scipy import sparse\n",
    "\n",
    "#sparse.save_npz(\"avito_ridge_final/targetenc_X.npz\", X)\n",
    "X = sparse.load_npz(\"avito_ridge_final/targetenc_X.npz\")\n",
    "#sparse.save_npz(\"avito_ridge_final/targetenc_testing.npz\", testing)\n",
    "testing = sparse.load_npz(\"avito_ridge_final/targetenc_testing.npz\")\n",
    "\n",
    "#y.to_pickle('avito_ridge_final/targetenc_y.pkl')    #to save the dataframe, df to 123.pkl\n",
    "y = pd.read_pickle('avito_ridge_final/y.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "#with open(\"avito_ridge_final/targetenc_tfvocab.txt\", \"wb\") as fp:   #Pickling \n",
    "#    pickle.dump(tfvocab, fp)\n",
    "\n",
    "with open(\"avito_ridge_final/targetenc_tfvocab.txt\", \"rb\") as fp:   # Unpickling\n",
    "    tfvocab = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del tfvocab\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "VALID = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modeling Stage\n",
      "Light Gradient Boosting Regressor\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModeling Stage\")\n",
    "\n",
    "# del ridge_preds,vectorizer,ready_df\n",
    "# gc.collect();\n",
    "    \n",
    "print(\"Light Gradient Boosting Regressor\")\n",
    "lgbm_params =  {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    # 'max_depth': 15,\n",
    "    'num_leaves': 270,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 2,\n",
    "    'learning_rate': 0.016,\n",
    "    'verbose': 0\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[100]\ttrain's rmse: 0.222813\tvalid's rmse: 0.224003\n",
      "[200]\ttrain's rmse: 0.21726\tvalid's rmse: 0.21958\n",
      "[300]\ttrain's rmse: 0.214703\tvalid's rmse: 0.218283\n",
      "[400]\ttrain's rmse: 0.212768\tvalid's rmse: 0.217615\n",
      "[500]\ttrain's rmse: 0.211104\tvalid's rmse: 0.217161\n",
      "[600]\ttrain's rmse: 0.209709\tvalid's rmse: 0.216897\n",
      "[700]\ttrain's rmse: 0.208434\tvalid's rmse: 0.216722\n",
      "[800]\ttrain's rmse: 0.207273\tvalid's rmse: 0.216602\n",
      "[900]\ttrain's rmse: 0.206175\tvalid's rmse: 0.216511\n",
      "[1000]\ttrain's rmse: 0.20515\tvalid's rmse: 0.216462\n",
      "[1100]\ttrain's rmse: 0.204192\tvalid's rmse: 0.21643\n",
      "[1200]\ttrain's rmse: 0.203236\tvalid's rmse: 0.216405\n",
      "[1300]\ttrain's rmse: 0.202345\tvalid's rmse: 0.216384\n",
      "[1400]\ttrain's rmse: 0.201436\tvalid's rmse: 0.216367\n",
      "[1500]\ttrain's rmse: 0.200568\tvalid's rmse: 0.21635\n",
      "Early stopping, best iteration is:\n",
      "[1537]\ttrain's rmse: 0.200251\tvalid's rmse: 0.216342\n",
      "Wall time: 4h 10min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if VALID == True:\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, test_size=0.10, random_state=2018)\n",
    "        \n",
    "    # LGBM Dataset Formatting \n",
    "    lgtrain = lgb.Dataset(X_train, y_train#,\n",
    "                    #feature_name=tfvocab,\n",
    "                    #categorical_feature = categorical\n",
    "                         )\n",
    "    lgvalid = lgb.Dataset(X_valid, y_valid#,\n",
    "                    #feature_name=tfvocab,\n",
    "                    #categorical_feature = categorical\n",
    "                         )\n",
    "    #del X, X_train; gc.collect()\n",
    "    \n",
    "    # Go Go Go\n",
    "    lgb_clf = lgb.train(\n",
    "        lgbm_params,\n",
    "        lgtrain,\n",
    "        num_boost_round=20000,\n",
    "        valid_sets=[lgtrain, lgvalid],\n",
    "        valid_names=['train','valid'],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=100\n",
    "    )\n",
    "#     print(\"Model Evaluation Stage\")\n",
    "#     print('RMSE:', np.sqrt(metrics.mean_squared_error(y_valid, lgb_clf.predict(X_valid))))\n",
    "    #del X_valid ; gc.collect()\n",
    "\n",
    "else:\n",
    "    # LGBM Dataset Formatting \n",
    "    lgtrain = lgb.Dataset(X, y,\n",
    "#                     feature_name=tfvocab,\n",
    "#                     categorical_feature = categorical\n",
    "                         )\n",
    "    #del X; gc.collect()\n",
    "    # Go Go Go\n",
    "    lgb_clf = lgb.train(\n",
    "        lgbm_params,\n",
    "        lgtrain,\n",
    "        num_boost_round=1537,\n",
    "        verbose_eval=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['avito_ridge_final/lgb_clf_targetenc.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "# save model\n",
    "joblib.dump(lgb_clf, 'avito_ridge_final/lgb_clf_targetenc.pkl')\n",
    "# load model\n",
    "#gbm_pickle = joblib.load('lgb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x1d6f559b080>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# # Feature Importance Plot\n",
    "# f, ax = plt.subplots(figsize=[7,10])\n",
    "# lgb.plot_importance(lgb_clf, max_num_features=100, ax=ax)\n",
    "# plt.title(\"Light GBM Feature Importance\")\n",
    "# plt.savefig('feature_import.png')\n",
    "# f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Stage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\longwind48\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:447: UserWarning: Converting data to scipy sparse matrix.\n",
      "  warnings.warn('Converting data to scipy sparse matrix.')\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Evaluation Stage\")\n",
    "lgpred = lgb_clf.predict(testing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Mixing lightgbm with ridge. I haven't really tested if this improves the score or not\n",
    "#blend = 0.95*lgpred + 0.05*ridge_oof_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lgsub = pd.DataFrame(lgpred,columns=[\"deal_probability\"],index=testdex)\n",
    "lgsub = lgsub['deal_probability'].clip(0.0, 1.0)\n",
    "lgsub.to_csv(\"final_ridge_targetenc-216342-.csv\",index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print(\"Model Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))\n",
    "print(\"Notebook Runtime: %0.2f Minutes\"%((time.time() - notebookstart)/60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
